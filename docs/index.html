<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>NeuroSeg Meets DINOv3</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    /* ---------- Global ---------- */
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, "SF Pro Text",
                   "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      background-color: #f3f4f6; /* 淡灰色背景 */
      color: #111827;           /* 深灰文字 */
      -webkit-font-smoothing: antialiased;
      line-height: 1.6;
    }

    img {
      max-width: 100%;
      height: auto;
      display: block;
    }

    .page {
      max-width: 1080px;
      margin: 0 auto;
      padding: 32px 16px 64px 16px;
    }

    /* ---------- Hero (Title) ---------- */
    .hero {
      background: #ffffff;
      border-radius: 24px;
      padding: 40px 24px 32px 24px;
      text-align: center;
      box-shadow: 0 18px 40px rgba(15, 23, 42, 0.06);
      margin-bottom: 32px;
    }

    .hero-title {
      font-size: clamp(2rem, 3vw + 1rem, 2.8rem);
      font-weight: 600;
      letter-spacing: 0.02em;
      color: #111827;
      margin-bottom: 10px;
    }

    .hero-subtitle {
      font-size: 1rem;
      color: #4b5563;
      max-width: 640px;
      margin: 0 auto;
    }

    /* ---------- Generic sections ---------- */

    .section {
      border-radius: 24px;
      padding: 32px 24px;
      margin-bottom: 24px;
      background: #ffffff;
    }

    .section.alt {
      background: #f9fafb; /* 更浅一点的灰白，层次 */
    }

    .section-title {
      font-size: 1.4rem;
      font-weight: 600;
      text-align: center;
      margin-bottom: 20px;
      color: #111827;
    }

    .section-body {
      max-width: 860px;
      margin: 0 auto;
      font-size: 0.98rem;
      color: #374151;
    }

    .section-body p + p {
      margin-top: 0.75rem;
    }

    /* ---------- Figures ---------- */

    .figure-wrapper {
      max-width: 900px;
      margin: 0 auto;
    }

    .figure-box {
      background: #ffffff;
      border-radius: 18px;
      border: 1px solid #e5e7eb;
      overflow: hidden;
      box-shadow: 0 10px 24px rgba(15, 23, 42, 0.04);
    }

    .figure-caption {
      font-size: 0.85rem;
      color: #6b7280;
      padding: 10px 14px 12px 14px;
      border-top: 1px solid #e5e7eb;
      background: #f9fafb;
    }

    /* ---------- Responsive tweaks ---------- */

    @media (max-width: 640px) {
      .hero {
        padding: 28px 18px 24px 18px;
        border-radius: 20px;
      }

      .section {
        padding: 24px 18px;
        border-radius: 20px;
      }

      .section-title {
        font-size: 1.2rem;
      }
    }
  </style>
</head>
<body>
  <div class="page">

    <!-- Title -->
    <header class="hero">
      <h1 class="hero-title">
        NeuroSeg Meets DINOv3: Transferring 2D Self-Supervised Visual Priors
        to 3D Neuron Segmentation via DINOv3 Initialization
      </h1>
      <p class="hero-subtitle">
        A framework for bringing powerful 2D DINOv3 ConvNeXt representations into 3D neuron segmentation,
        improving thin-structure reconstruction and label efficiency.
      </p>
    </header>

    <!-- Teaser image -->
    <section class="section">
      <h2 class="section-title">Teaser</h2>
      <div class="figure-wrapper">
        <div class="figure-box">
          <img src="teaser.png" alt="NeurINO teaser figure" />
          <div class="figure-caption">
            NeurINO transfers self-supervised 2D DINOv3 priors into a 3D segmentation framework,
            leading to improved reconstruction of fine neuronal structures.
          </div>
        </div>
      </div>
    </section>

    <!-- Abstract -->
    <section class="section alt" id="abstract">
      <h2 class="section-title">Abstract</h2>
      <div class="section-body">
        <p>
          High-quality 3D neuron segmentation is critical for neuroscience, but densely labeled
          volumetric data are scarce and expensive to obtain. In contrast, 2D natural image datasets
          enable powerful self-supervised models such as DINOv3.
        </p>
        <p>
          We propose <strong>NeurINO</strong>, a framework that transfers 2D ConvNeXt-based DINOv3
          visual priors to 3D neuron segmentation by inflating kernels into a 3D architecture and
          carefully aligning feature statistics and normalization. Experiments on multiple neuron
          datasets show consistent gains in segmentation quality and thin-structure recall,
          especially in low-label regimes.
        </p>
      </div>
    </section>

    <!-- Method / Framework -->
    <section class="section" id="method">
      <h2 class="section-title">Method / Framework</h2>
      <div class="section-body">
        <p>
          NeurINO adopts a simple encoder–decoder design. A 2D DINOv3 ConvNeXt backbone is first
          converted into a 3D encoder by inflating convolutional kernels and adapting
          downsampling stages. The encoder is then coupled with a lightweight 3D decoder tailored
          to neuron morphology, with careful normalization replacement and optional bottleneck
          blocks to stabilize training.
        </p>
        <p>
          This design keeps most of the strong 2D visual priors while remaining compatible with
          standard 3D medical-imaging-style training pipelines.
        </p>
      </div>

      <div class="figure-wrapper" style="margin-top: 20px;">
        <div class="figure-box">
          <img src="method.png" alt="NeurINO method / framework diagram" />
          <div class="figure-caption">
            Overall framework. 2D DINOv3 ConvNeXt stages are inflated into 3D and plugged into a
            neuron-centric 3D decoder for volumetric segmentation.
          </div>
        </div>
      </div>
    </section>

    <!-- Results -->
    <section class="section alt" id="results">
      <h2 class="section-title">Results</h2>
      <div class="section-body">
        <p>
          Across several neuron datasets, NeurINO improves over strong 3D baselines in terms of
          Dice score and topological accuracy. The model better preserves long, thin neurites and
          reduces merge/split errors, particularly when only limited manual annotations are
          available.
        </p>
        <p>
          Qualitative visualizations highlight cleaner branch reconstruction and fewer broken
          structures, demonstrating the benefit of transferring 2D DINOv3 priors into 3D.
        </p>
      </div>

      <div class="figure-wrapper" style="margin-top: 20px;">
        <div class="figure-box">
          <img src="results.png" alt="NeurINO qualitative and quantitative results" />
          <div class="figure-caption">
            Example results. NeurINO produces more complete neuron reconstructions and reduces
            topological errors compared with baseline 3D segmentation models.
          </div>
        </div>
      </div>
    </section>

  </div>
</body>
</html>
